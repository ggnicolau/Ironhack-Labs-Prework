{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T14:20:09.091312Z",
     "start_time": "2020-06-10T14:20:08.964384Z"
    }
   },
   "source": [
    "![Ironhack logo](https://i.imgur.com/1QgrNNw.png)\n",
    "\n",
    "# Lab | Data Cleaning\n",
    "\n",
    "## Introduction\n",
    "\n",
    "We keep seeing a common phrase that 80% of the work of a data scientist is data cleaning. We have no idea whether this number is accurate but a data scientist indeed spends lots of time and effort in collecting, cleaning and preparing the data for analysis. This is because datasets are usually messy and complex in nature. It is a very important ability for a data scientist to refine and restructure datasets into a usable state in order to proceed to the data analysis stage.\n",
    "\n",
    "In this exercise, you will both practice the data cleaning techniques we discussed in the lesson and learn new techniques by looking up documentations and references. You will work on your own but remember the teaching staff is at your service whenever you encounter problems.\n",
    "\n",
    "## Getting Started\n",
    "\n",
    "Read the instructions for each cell and provide your answers. Make sure to test your answers in each cell and save. Jupyter Notebook should automatically save your work progress. But it's a good idea to periodically save your work manually just in case.\n",
    "\n",
    "\n",
    "## Resources\n",
    "\n",
    "[Data Cleaning Tutorial](https://www.tutorialspoint.com/python/python_data_cleansing.html)\n",
    "\n",
    "[Data Cleaning with Numpy and Pandas](https://realpython.com/python-data-cleaning-numpy-pandas/#python-data-cleaning-recap-and-resources)\n",
    "\n",
    "[Data Cleaning Video](https://www.youtube.com/watch?v=ZOX18HfLHGQ)\n",
    "\n",
    "[Data Preparation](https://www.kdnuggets.com/2017/06/7-steps-mastering-data-preparation-python.html)\n",
    "\n",
    "[Google Search](https://www.google.es/search?q=how+to+clean+data+with+python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-31T13:50:39.414148Z",
     "start_time": "2020-08-31T13:50:37.210115Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the users dataset.\n",
    "\n",
    "Take a look at what is the `users.csv` separator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-31T13:50:40.355543Z",
     "start_time": "2020-08-31T13:50:39.427434Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check its shape\n",
    "\n",
    "See the number of rows and columns you're dealing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-31T13:50:40.385523Z",
     "start_time": "2020-08-31T13:50:40.367533Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the .head() to see some rows of your dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-31T13:50:40.509450Z",
     "start_time": "2020-08-31T13:50:40.397517Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data info. \n",
    "\n",
    "Which columns have a great number of missing values? How many space does this dataframe is occupying in your memory?\n",
    "\n",
    "Expected output:\n",
    "````\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "RangeIndex: 40503 entries, 0 to 40502\n",
    "Data columns (total 14 columns):\n",
    " #   Column           Non-Null Count  Dtype  \n",
    "---  ------           --------------  -----  \n",
    " 0   Id               40503 non-null  int64  \n",
    " 1   Reputation       40503 non-null  int64  \n",
    " 2   CreationDate     40503 non-null  object \n",
    " 3   DisplayName      40497 non-null  object \n",
    " 4   LastAccessDate   40503 non-null  object \n",
    " 5   WebsiteUrl       8158 non-null   object \n",
    " 6   Location         11731 non-null  object \n",
    " 7   AboutMe          9424 non-null   object \n",
    " 8   Views            40503 non-null  int64  \n",
    " 9   UpVotes          40503 non-null  int64  \n",
    " 10  DownVotes        40503 non-null  int64  \n",
    " 11  AccountId        40503 non-null  int64  \n",
    " 12  Age              8352 non-null   float64\n",
    " 13  ProfileImageUrl  16540 non-null  object \n",
    "dtypes: float64(1), int64(6), object(7)\n",
    "memory usage: 4.3+ MB\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-31T13:50:40.703415Z",
     "start_time": "2020-08-31T13:50:40.531436Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename Id column to user_id.\n",
    "\n",
    "Remember to store you results back at the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-31T13:50:40.947345Z",
     "start_time": "2020-08-31T13:50:40.726418Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the `posts.csv` dataset.\n",
    "\n",
    "Note that this is a `gzip compressed csv`. In order to read this file correctly, you'll have to read the documentation (or help) of your `pd.read_csv()` function and check the `compression` argument. Try to understand which value of `compression=...` you should put in order to read your dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-31T13:50:52.177093Z",
     "start_time": "2020-08-31T13:50:40.959336Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-31T13:50:52.781751Z",
     "start_time": "2020-08-31T13:50:52.185089Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform the same as above to understand a bit of your data (head, info, shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-31T13:50:52.809734Z",
     "start_time": "2020-08-31T13:50:52.790741Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-31T13:50:52.979638Z",
     "start_time": "2020-08-31T13:50:52.820726Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-31T13:50:53.300469Z",
     "start_time": "2020-08-31T13:50:52.991631Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename Id column to post_id and OwnerUserId to user_id.\n",
    "\n",
    "Again, remember to check that your results are correctly stored inside the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-31T13:50:53.380426Z",
     "start_time": "2020-08-31T13:50:53.310466Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define new dataframes for users and posts with the following selected columns:\n",
    "\n",
    "**users columns**: user_id, Reputation, Views, UpVotes, DownVotes  \n",
    "**posts columns**: post_id, Score, user_id, ViewCount, CommentCount, Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-31T13:50:53.444406Z",
     "start_time": "2020-08-31T13:50:53.387419Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Check the new posts dataframe's info. What is the most noticeable change? \n",
    "\n",
    "Explain why we have chosen only some columns of it in terms of efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge the new dataframes you have created, of users and posts. Create a dataframe called `posts_from_users`\n",
    "\n",
    "You will need to make an inner [merge](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.merge.html) of posts and users dataframes. \n",
    "\n",
    "Think carefully which should be the key(s) for your merging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-31T13:50:53.822208Z",
     "start_time": "2020-08-31T13:50:53.454404Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-31T13:50:53.931147Z",
     "start_time": "2020-08-31T13:50:53.832204Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the number of duplicated rows.\n",
    "\n",
    "Remember you can sum the results of a mask to get how many numbers the True value appeared in the results. This occurs because `True` is interpreted as `1` in Python whereas `False` is interpreted as `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-31T13:50:54.630016Z",
     "start_time": "2020-08-31T13:50:53.940142Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find those duplicate values and try to understand what happened.\n",
    "\n",
    "*Hint:* You can use the argument `keep=False` from the `.duplicated()` method to bring the duplication.\n",
    "\n",
    "*Hint 2:* You can sort the values `by=['user_id', 'post_id']` to see them in order.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-31T13:50:55.253927Z",
     "start_time": "2020-08-31T13:50:54.639008Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Should you drop it? If you think it is reasonable to drop it, then drop it.\n",
    "\n",
    "Think: How would you correct it in the first place? That is, what was wrong in the first place?\n",
    "\n",
    "*Hint:* There's a pandas method to drop duplicates. If you wanted to do it by hand, you could select the indexes of the duplicated values and `.drop()` it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-31T13:50:55.823212Z",
     "start_time": "2020-08-31T13:50:55.266922Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. How many missing values do you have in your merged dataframe? On which columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-31T13:50:55.907162Z",
     "start_time": "2020-08-31T13:50:55.832207Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select only the rows in which there at least some missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-31T13:50:56.190003Z",
     "start_time": "2020-08-31T13:50:55.916157Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You will need to make something with missing values.  Will you clean or filling them? \n",
    "\n",
    "Pay attention. There can be different reasons for the missings numbers. Look at the `user_id` of some of them, look at the body of the message. Which ones you're sure of what should be and which one can you infer? Don't hurry up, take a look at your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-31T13:50:56.376894Z",
     "start_time": "2020-08-31T13:50:56.201995Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-31T13:50:56.565787Z",
     "start_time": "2020-08-31T13:50:56.386889Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjust the data types in order to avoid future issues. Which ones should be changed? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-31T13:50:56.645740Z",
     "start_time": "2020-08-31T13:50:56.575779Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-31T13:50:56.769669Z",
     "start_time": "2020-08-31T13:50:56.654736Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus 1: (filtering) What is the average number of comments for users who are above the average reputation?\n",
    "\n",
    "*Hint:* Calculate the average of the user Reputation. Store it in a variable called `avg_reputation` and then use that variable for filtering the dataset and generating the results for each case (for the case in which `Reputation > {avg_reputation}` and etc.\n",
    "\n",
    "*Hint 2:* You could create a variable based on that condition and use the group by function perform the task above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-31T13:50:56.802650Z",
     "start_time": "2020-08-31T13:50:56.784662Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-31T13:50:56.836631Z",
     "start_time": "2020-08-31T13:50:56.812644Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-31T13:50:56.995540Z",
     "start_time": "2020-08-31T13:50:56.851623Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus 2: (grouping) Group your dataframe by the Reputation of your user. Calculate the mean value of ViewCount and CommentCount for each reputation value.\n",
    "\n",
    "Suppose the missing values on ViewCount are due a systemic error and you wanted to guess what values should have been there in the first place, but the system abended.\n",
    "\n",
    "Would that be an interesting candidate for inputting the value for the missing `ViewCount` values? If so, input it with these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-31T13:50:57.090486Z",
     "start_time": "2020-08-31T13:50:57.007532Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## refs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample database used: https://relational.fit.cvut.cz/dataset/Stats\n",
    "\n",
    "Stack-overflow database: https://www.brentozar.com/archive/2015/10/how-to-download-the-stack-overflow-database-via-bittorrent/\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
