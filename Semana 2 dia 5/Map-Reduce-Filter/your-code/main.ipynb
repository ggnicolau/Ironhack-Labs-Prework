{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h0plEKnhEQ4Z"
   },
   "source": [
    "![Ironhack logo](https://i.imgur.com/1QgrNNw.png)\n",
    "\n",
    "# Lab | Map, Reduce, Filter\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lab, we will implement what we have learned about functional programming using the map, reduce, and filter functions. These functions allow us to pass an input and a transformation to a function and produce an output. \n",
    "\n",
    "## Getting Started\n",
    "\n",
    "Follow the instructions and add your code and explanations as necessary. By the end of this lab, you will have learned about mapping, reducing, and filtering as well as applying functions in Pandas.\n",
    "\n",
    "\n",
    "## Resources\n",
    "\n",
    "[The Official Python Documentation on Mapping, Reducing, and Filtering](https://docs.python.org/3/howto/functional.html#built-in-functions)\n",
    "\n",
    "[The `apply` Function in Pandas](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.apply.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wk5IDgMsrJtc"
   },
   "source": [
    "# Before your start:\n",
    "- Comment as much as you can\n",
    "- Happy learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T20:06:13.200522Z",
     "start_time": "2021-04-02T20:06:13.196533Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "hza0fiD_rJti"
   },
   "outputs": [],
   "source": [
    "# Import reduce from functools, numpy and pandas\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uG22b-G6rJtn"
   },
   "source": [
    "# Challenge 1 - Mapping\n",
    "\n",
    "#### We will use the map function to clean up words in a book.\n",
    "\n",
    "In the following cell, we will read a text file containing the book The Prophet by Khalil Gibran."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T20:24:04.135913Z",
     "start_time": "2021-04-02T20:24:04.130928Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "O4U5RlJvrJtp"
   },
   "outputs": [],
   "source": [
    "# Run this code:\n",
    "\n",
    "location = 'C:/Users/user/1.IRONHACK/Ironhack Labs/Semana 2 dia 5/Map-Reduce-Filter/data/58585-0.txt'\n",
    "with open(location, 'r', encoding=\"utf8\") as f:\n",
    "    prophet = f.read().split(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RG45u3K0rJtv"
   },
   "source": [
    "#### Let's remove the first 568 words since they contain information about the book but are not part of the book itself. \n",
    "\n",
    "Do this by removing from `prophet` elements 0 through 567 of the list (you can also do this by keeping elements 568 through the last element)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T20:39:46.463261Z",
     "start_time": "2021-04-02T20:39:46.431364Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "lGIJTTKlrJtw"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['terms\\nof',\n",
       " 'Gibran\\n\\nRelease',\n",
       " 'January',\n",
       " 'Page',\n",
       " 'text',\n",
       " 'Alfred',\n",
       " 'Original',\n",
       " 'universal',\n",
       " 'KAHLIL',\n",
       " '1920',\n",
       " 'Gods.',\n",
       " 'Nymphs',\n",
       " 'Children.................21\\n',\n",
       " 'Sorrow...........33\\n',\n",
       " 'Freedom..................55\\n',\n",
       " 'Good',\n",
       " 'On',\n",
       " 'On',\n",
       " 'On',\n",
       " 'On',\n",
       " 'the{7}',\n",
       " 'to\\nreturn',\n",
       " 'seventh\\nday',\n",
       " 'flew',\n",
       " 'prayed',\n",
       " 'sadness\\ncame',\n",
       " 'without\\nregret?\\n\\nToo',\n",
       " 'own\\nhands.\\n\\nNor',\n",
       " 'thirst.\\n\\n*****\\n\\nYet',\n",
       " 'is\\nhere.',\n",
       " 'ether.\\n\\nAnd',\n",
       " 'sea,\\nand',\n",
       " 'cried',\n",
       " 'dream.\\n\\nReady',\n",
       " '{10}And',\n",
       " 'a\\nboundless',\n",
       " 'city\\ngates.\\n\\nAnd',\n",
       " 'coming',\n",
       " 'has\\nleft',\n",
       " '{11}Shall',\n",
       " 'flow',\n",
       " 'me?\\n\\nA',\n",
       " 'seed,',\n",
       " 'flame\\nthat',\n",
       " 'raise',\n",
       " 'much\\nin',\n",
       " 'forth\\nand',\n",
       " 'us\\ndreams',\n",
       " 'years',\n",
       " 'veils',\n",
       " 'him.\\nBut',\n",
       " 'falling',\n",
       " 'believed',\n",
       " 'long',\n",
       " 'place\\nof',\n",
       " 'it\\nshall',\n",
       " 'weeping',\n",
       " 'and\\ndeath.\\n\\n*****\\n\\nAnd',\n",
       " 'looked',\n",
       " 'to\\nhim,\\n\\nThough',\n",
       " 'crowns',\n",
       " 'and\\n{16}caresses',\n",
       " 'and\\nshake',\n",
       " 'sifts',\n",
       " 'a\\nfragment',\n",
       " 'you\\ncover',\n",
       " 'itself.\\n\\nLove',\n",
       " 'directs',\n",
       " 'brook',\n",
       " 'thanks',\n",
       " 'with\\ngratitude;\\n\\nAnd',\n",
       " '_Marriage_',\n",
       " 'you\\nshall',\n",
       " 'white\\nwings',\n",
       " 'bond',\n",
       " 'cup.\\n\\nGive',\n",
       " 'quiver',\n",
       " 'Life',\n",
       " 'shadow.\\n\\n[Illustration:',\n",
       " 'of\\nLife’s',\n",
       " 'their\\nsouls,\\n\\nFor',\n",
       " 'tarries',\n",
       " 'mark',\n",
       " 'bending',\n",
       " '*****\\n\\n{23}Then',\n",
       " 'you\\ntruly',\n",
       " 'bones\\nin',\n",
       " 'dread',\n",
       " 'hidden\\ndesire',\n",
       " 'is\\nnever',\n",
       " 'seek\\njoy,',\n",
       " 'valley',\n",
       " 'earth.\\n\\n[Illustration:',\n",
       " 'greater\\nthan',\n",
       " 'now,',\n",
       " 'his\\ndays',\n",
       " 'charity,',\n",
       " 'unabashed?\\n\\nSee',\n",
       " 'deem',\n",
       " 'are\\nall',\n",
       " 'overmindful',\n",
       " '*****\\n\\n{27}Then',\n",
       " 'light.\\n\\nBut',\n",
       " 'an\\nact',\n",
       " 'man.\\n\\n*****\\n\\nWhen',\n",
       " 'slain;',\n",
       " 'but\\nthe',\n",
       " 'heart,\\n\\n“Your',\n",
       " 'shall\\nblossom',\n",
       " 'the\\nwinepress,',\n",
       " 'draw',\n",
       " 'for\\nthe',\n",
       " 'become',\n",
       " 'towards',\n",
       " 'dumb',\n",
       " 'was\\nborn,\\n\\nAnd',\n",
       " 'secret.\\n\\n*****\\n\\nBut',\n",
       " 'sweat',\n",
       " 'is\\nwritten.\\n\\nYou',\n",
       " 'yourself,',\n",
       " 'threads\\ndrawn',\n",
       " 'if\\nyour',\n",
       " 'dead\\nare',\n",
       " '{33}And',\n",
       " 'the\\nwind',\n",
       " 'grass;\\n\\nAnd',\n",
       " 'loving.\\n\\n*****\\n\\nWork',\n",
       " 'at\\nthe',\n",
       " 'bread',\n",
       " 'the\\ngrapes,',\n",
       " '{34}And',\n",
       " 'voices',\n",
       " 'rises',\n",
       " 'carves',\n",
       " 'burned',\n",
       " 'joyous,',\n",
       " 'is\\ngiving',\n",
       " 'weeping',\n",
       " '“Joy',\n",
       " 'are\\ninseparable.\\n\\nTogether',\n",
       " 'at\\nstandstill',\n",
       " 'silver,',\n",
       " 'bower',\n",
       " 'walls.\\n\\nFor',\n",
       " 'body.\\n\\nIt',\n",
       " 'dream?\\nand',\n",
       " 'meadow.\\n\\nWould',\n",
       " 'through\\nvineyards,',\n",
       " 'little\\nlonger',\n",
       " 'And',\n",
       " 'lust\\nfor',\n",
       " 'scourge',\n",
       " 'bed',\n",
       " 'funeral.\\n\\nBut',\n",
       " 'that\\n{40}covers',\n",
       " 'bend',\n",
       " 'crack',\n",
       " 'shelter',\n",
       " 'of\\n_Clothes_.\\n\\nAnd',\n",
       " 'conceal',\n",
       " 'harness',\n",
       " 'north',\n",
       " 'north',\n",
       " 'forest.',\n",
       " 'forget',\n",
       " '*****\\n\\n{43}And',\n",
       " 'how\\nto',\n",
       " 'the\\nearth',\n",
       " 'and\\nkindly',\n",
       " 'the\\ngatherers',\n",
       " 'weighs',\n",
       " 'would\\nsell',\n",
       " 'us.”\\n\\n*****\\n\\nAnd',\n",
       " 'gifts',\n",
       " 'bring,\\nthough',\n",
       " 'are\\nsatisfied.\\n\\n*****',\n",
       " 'wandering\\nupon',\n",
       " 'undefiled.\\n\\nAnd',\n",
       " 'man,',\n",
       " 'shapeless',\n",
       " 'god-self',\n",
       " 'crime.\\n\\n*****\\n\\nOftentimes',\n",
       " 'stranger',\n",
       " 'fall\\nlower',\n",
       " '{47}So',\n",
       " 'wrong',\n",
       " 'procession',\n",
       " 'behind',\n",
       " 'against\\nthe',\n",
       " 'surer',\n",
       " 'blameless',\n",
       " 'clean',\n",
       " 'burden',\n",
       " 'breaks,',\n",
       " 'judgment\\nthe',\n",
       " 'fruitful',\n",
       " 'together',\n",
       " 'honest',\n",
       " 'lay',\n",
       " 'their\\nmisdeeds?\\n\\nIs',\n",
       " 'lay',\n",
       " 'guilty.\\n\\nUnbidden',\n",
       " 'upon\\nthemselves.',\n",
       " 'fullness\\nof',\n",
       " 'between',\n",
       " 'in\\nits',\n",
       " 'sand-towers',\n",
       " 'laughs',\n",
       " 'law\\na',\n",
       " 'likeness?',\n",
       " 'loves',\n",
       " 'deer',\n",
       " 'goes',\n",
       " 'down',\n",
       " 'hold\\nyou?\\n\\nYou',\n",
       " 'stumble',\n",
       " 'to\\njudgment',\n",
       " 'garment\\nyet',\n",
       " 'man’s',\n",
       " 'strings\\nof',\n",
       " 'freedom,\\n\\nEven',\n",
       " 'grief,\\n\\nBut',\n",
       " 'hour?\\n\\nIn',\n",
       " 'though\\nits',\n",
       " 'would\\nabolish,',\n",
       " 'would\\n{56}dethrone,',\n",
       " 'and\\nthe',\n",
       " 'tyranny',\n",
       " 'care',\n",
       " 'you.\\n\\nAnd',\n",
       " 'desired\\nand',\n",
       " 'pursued',\n",
       " 'shadows',\n",
       " 'freedom',\n",
       " 'becomes',\n",
       " 'spoke',\n",
       " 'against',\n",
       " 'discord\\nand',\n",
       " 'yourselves\\nbe',\n",
       " 'either',\n",
       " 'toss',\n",
       " 'standstill',\n",
       " 'passion,\\nunattended,',\n",
       " 'exalt',\n",
       " 'it\\nmay',\n",
       " 'passion',\n",
       " 'guest\\nabove',\n",
       " 'the\\nfaith',\n",
       " 'shade',\n",
       " 'peace',\n",
       " 'meadows--then',\n",
       " 'heart\\nsay',\n",
       " 'passion.”\\n\\nAnd',\n",
       " 'stand',\n",
       " 'your\\npain',\n",
       " 'your\\nheart,',\n",
       " 'bitter',\n",
       " 'is\\nguided',\n",
       " 'with\\nHis',\n",
       " 'sacred',\n",
       " 'you\\nhave',\n",
       " 'well-spring',\n",
       " 'murmuring',\n",
       " 'revealed',\n",
       " 'your\\nunknown',\n",
       " 'boundless',\n",
       " '“I',\n",
       " 'neither\\ndoes',\n",
       " 'itself,',\n",
       " 'teacher,',\n",
       " 'asleep',\n",
       " 'wisdom',\n",
       " 'house',\n",
       " 'musician',\n",
       " 'it.\\n{65}And',\n",
       " 'measure,',\n",
       " 'alone\\nin',\n",
       " 'God’s',\n",
       " 'so',\n",
       " 'answered.\\n\\nHe',\n",
       " 'friend',\n",
       " '“ay.”\\n\\nAnd',\n",
       " 'heart;\\n\\nFor',\n",
       " 'shared,',\n",
       " 'you\\ngrieve',\n",
       " 'plain.',\n",
       " 'spirit.\\n\\nFor',\n",
       " 'the\\nunprofitable',\n",
       " 'him',\n",
       " 'friend',\n",
       " 'him',\n",
       " 'him',\n",
       " 'emptiness.\\n\\nAnd',\n",
       " 'laughter,',\n",
       " 'finds',\n",
       " 'morning',\n",
       " 'of\\n_Talking_.\\n\\nAnd',\n",
       " 'talk',\n",
       " 'live',\n",
       " 'cage',\n",
       " 'aloneness',\n",
       " 'there',\n",
       " 'tell',\n",
       " 'friend',\n",
       " 'move',\n",
       " 'ear;\\n\\nFor',\n",
       " 'truth',\n",
       " 'measureless\\nand',\n",
       " 'adjust',\n",
       " 'direct',\n",
       " 'course',\n",
       " 'watch',\n",
       " 'first',\n",
       " 'feel',\n",
       " 'thought',\n",
       " 'time',\n",
       " 'thought',\n",
       " 'each',\n",
       " 'seasons,\\n\\nAnd',\n",
       " 'today',\n",
       " 'one',\n",
       " 'Evil_.\\n\\nAnd',\n",
       " 'answered:\\n\\nOf',\n",
       " 'hunger',\n",
       " 'thirst?\\n\\nVerily',\n",
       " 'thirsts\\nit',\n",
       " 'one',\n",
       " 'one',\n",
       " 'house',\n",
       " 'wander\\naimlessly',\n",
       " 'bottom.',\n",
       " 'ripe',\n",
       " 'fruit',\n",
       " 'need,',\n",
       " 'speech,\\n\\nYet',\n",
       " 'speech',\n",
       " 'tongue.\\n\\nYou',\n",
       " 'goal\\nfirmly',\n",
       " 'limp',\n",
       " 'good,\\n\\nYou',\n",
       " 'stags',\n",
       " 'a\\ntorrent',\n",
       " 'secrets',\n",
       " 'that\\nloses',\n",
       " 'let',\n",
       " 'him',\n",
       " 'are\\nyou',\n",
       " '“What',\n",
       " 'saying:\\n\\nYou',\n",
       " 'should\\nspur',\n",
       " 'those',\n",
       " 'very\\n{77}hour,',\n",
       " 'save',\n",
       " 'let',\n",
       " 'for\\nno',\n",
       " 'shall\\nnot',\n",
       " 'pray',\n",
       " 'save',\n",
       " 'prayer',\n",
       " 'seas\\ncan',\n",
       " 'prayer',\n",
       " 'thy',\n",
       " 'turn',\n",
       " 'art',\n",
       " 'more\\nof',\n",
       " 'Speak\\nto',\n",
       " 'deep',\n",
       " 'singing.\\n\\nSome',\n",
       " 'elders',\n",
       " 'comforts',\n",
       " 'there',\n",
       " 'those',\n",
       " 'it.\\n\\nBut',\n",
       " 'their\\npleasure.\\n\\nAnd',\n",
       " 'too',\n",
       " 'dig',\n",
       " 'quivering',\n",
       " 'tell',\n",
       " 'who',\n",
       " 'the\\nstillness',\n",
       " 'pool\\nwhich',\n",
       " 'being.\\n\\nWho',\n",
       " 'knows',\n",
       " 'body',\n",
       " 'bring',\n",
       " 'ask',\n",
       " 'gardens,',\n",
       " 'bee',\n",
       " 'bee',\n",
       " 'giving\\nand',\n",
       " 'your\\npleasures',\n",
       " 'said,',\n",
       " 'way',\n",
       " 'speech?\\n\\nThe',\n",
       " 'own\\nglory',\n",
       " 'say,',\n",
       " 'say,',\n",
       " 'faint',\n",
       " 'say,',\n",
       " 'say,',\n",
       " 'leaping',\n",
       " 'reapers\\nsay,',\n",
       " '{85}All',\n",
       " 'beauty,\\n\\nYet',\n",
       " 'truth',\n",
       " 'spoke',\n",
       " 'ecstasy.\\n\\nIt',\n",
       " 'forth,\\n\\nBut',\n",
       " 'enflamed',\n",
       " 'song',\n",
       " 'furrowed\\nbark,',\n",
       " 'said,',\n",
       " 'Speak',\n",
       " '_Religion_.\\n\\nAnd',\n",
       " 'said:\\n\\nHave',\n",
       " 'deeds',\n",
       " 'wonder',\n",
       " 'the\\nloom?\\n\\nWho',\n",
       " 'hours',\n",
       " 'body?”\\n\\nAll',\n",
       " 'hours',\n",
       " 'self',\n",
       " 'his',\n",
       " 'better',\n",
       " 'tear',\n",
       " 'his',\n",
       " 'who',\n",
       " 'his',\n",
       " 'his',\n",
       " 'song',\n",
       " 'but',\n",
       " 'house',\n",
       " 'his',\n",
       " 'soul',\n",
       " 'daily',\n",
       " 'your\\nreligion.\\n\\nWhenever',\n",
       " 'plough',\n",
       " 'revery',\n",
       " 'fall',\n",
       " 'cannot',\n",
       " 'yourself',\n",
       " 'would',\n",
       " 'God',\n",
       " 'lightning',\n",
       " 'Him',\n",
       " 'waving',\n",
       " 'saying,',\n",
       " 'would',\n",
       " 'cannot',\n",
       " 'would',\n",
       " 'one,',\n",
       " 'heart',\n",
       " 'them',\n",
       " 'gate',\n",
       " 'but',\n",
       " 'him',\n",
       " 'his\\ntrembling?\\n\\n*****\\n\\nFor',\n",
       " 'but',\n",
       " 'stand',\n",
       " 'but\\nto',\n",
       " 'rise',\n",
       " 'God',\n",
       " 'when',\n",
       " 'your\\nlimbs,',\n",
       " 'truly',\n",
       " 'said,',\n",
       " 'spirit\\nthat',\n",
       " 'spoken.\\n\\nAnd',\n",
       " 'he',\n",
       " 'answered,',\n",
       " 'who',\n",
       " 'listener?\\n\\n*****\\n\\nThen',\n",
       " 'he',\n",
       " 'descended',\n",
       " 'the\\nTemple',\n",
       " 'he',\n",
       " 'his',\n",
       " 'again,',\n",
       " 'he',\n",
       " 'raised\\nhis',\n",
       " 'Orphalese,',\n",
       " 'seeking',\n",
       " 'finds',\n",
       " 'the\\nearth',\n",
       " 'tenacious\\nplant,',\n",
       " 'ripeness',\n",
       " 'heart',\n",
       " 'among',\n",
       " 'you,',\n",
       " 'again,\\n\\nAnd',\n",
       " 'heart',\n",
       " 'though',\n",
       " 'death',\n",
       " 'hide',\n",
       " 'me,',\n",
       " 'aught',\n",
       " 'go',\n",
       " 'but',\n",
       " 'down',\n",
       " 'love,',\n",
       " 'let',\n",
       " 'till',\n",
       " 'change,',\n",
       " 'but',\n",
       " 'his',\n",
       " 'his',\n",
       " 'his',\n",
       " 'should\\nsatisfy',\n",
       " 'his',\n",
       " 'needs.\\n\\nKnow',\n",
       " 'return.\\n\\nThe',\n",
       " 'but',\n",
       " 'shall\\nrise',\n",
       " 'gather',\n",
       " 'down',\n",
       " 'rain.\\n\\nAnd',\n",
       " 'mist',\n",
       " 'night',\n",
       " 'have\\nwalked',\n",
       " 'spirit\\nhas',\n",
       " 'oftentimes',\n",
       " 'among',\n",
       " 'youths',\n",
       " 'when',\n",
       " 'yet',\n",
       " '0119]\\n\\nBut',\n",
       " 'laughter',\n",
       " 'boundless',\n",
       " 'man',\n",
       " 'him',\n",
       " 'you\\nand',\n",
       " 'oak',\n",
       " 'apple\\nblossoms',\n",
       " 'man',\n",
       " 'lifts',\n",
       " 'into',\n",
       " 'told',\n",
       " 'even',\n",
       " 'but',\n",
       " 'truth.',\n",
       " 'strong',\n",
       " 'link.\\n\\nTo',\n",
       " 'your',\n",
       " 'its',\n",
       " 'your',\n",
       " 'failures',\n",
       " 'to\\ncast',\n",
       " 'like',\n",
       " 'though',\n",
       " 'tide',\n",
       " 'your',\n",
       " 'cannot',\n",
       " 'like',\n",
       " 'though',\n",
       " 'your',\n",
       " 'your\\nspring,\\n\\nYet',\n",
       " 'you,',\n",
       " 'say',\n",
       " 'things',\n",
       " 'say',\n",
       " 'one',\n",
       " 'but\\nthe',\n",
       " 'good',\n",
       " 'words',\n",
       " 'thought.\\n\\nAnd',\n",
       " 'what',\n",
       " 'knowledge',\n",
       " 'but',\n",
       " 'words',\n",
       " 'ancient',\n",
       " 'when',\n",
       " 'earth\\nknew',\n",
       " 'us',\n",
       " 'when',\n",
       " 'earth',\n",
       " 'men',\n",
       " 'wisdom.\\n\\nIt',\n",
       " 'spirit',\n",
       " 'you,',\n",
       " 'its',\n",
       " 'your',\n",
       " 'fear',\n",
       " 'mountains',\n",
       " 'pass',\n",
       " 'your',\n",
       " 'look',\n",
       " 'yourselves\\nand',\n",
       " 'your',\n",
       " 'children',\n",
       " 'unto',\n",
       " 'your',\n",
       " 'but',\n",
       " 'power',\n",
       " 'than',\n",
       " 'given,',\n",
       " 'been',\n",
       " 'me.\\n\\nYou',\n",
       " 'there',\n",
       " 'his',\n",
       " 'into',\n",
       " 'it.\\n\\n*****\\n\\nSome',\n",
       " 'deemed',\n",
       " 'proud',\n",
       " 'though',\n",
       " 'when',\n",
       " 'would',\n",
       " 'your',\n",
       " 'temple\\nwhen',\n",
       " 'would',\n",
       " 'me,\\n\\nYet',\n",
       " 'your',\n",
       " 'mindfulness\\nof',\n",
       " 'nights',\n",
       " 'give',\n",
       " 'know',\n",
       " 'all.',\n",
       " 'that\\ngazes',\n",
       " 'turns',\n",
       " 'good',\n",
       " 'calls',\n",
       " 'becomes',\n",
       " 'parent',\n",
       " 'a\\ncurse.\\n\\n*****\\n\\nAnd',\n",
       " 'drunk',\n",
       " 'said,',\n",
       " 'but',\n",
       " 'walked',\n",
       " 'remote',\n",
       " 'save',\n",
       " 'distance?\\n\\nHow',\n",
       " 'one',\n",
       " 'he',\n",
       " 'be\\ntar?\\n\\nAnd',\n",
       " 'among',\n",
       " 'called',\n",
       " 'unto',\n",
       " 'me,',\n",
       " 'stranger,',\n",
       " 'seek',\n",
       " 'the\\nunattainable?\\n\\nWhat',\n",
       " 'would',\n",
       " 'your',\n",
       " 'what',\n",
       " 'one',\n",
       " 'us.\\n\\nDescend',\n",
       " 'appease',\n",
       " 'your',\n",
       " 'hunger',\n",
       " 'your',\n",
       " 'our\\nwine.”\\n\\nIn',\n",
       " 'their',\n",
       " 'souls',\n",
       " 'were',\n",
       " 'their',\n",
       " 'deeper',\n",
       " 'but',\n",
       " 'your',\n",
       " 'your',\n",
       " 'your',\n",
       " 'seek',\n",
       " 'own',\n",
       " 'when',\n",
       " 'wings',\n",
       " 'were',\n",
       " 'their',\n",
       " 'earth',\n",
       " 'believer',\n",
       " 'have',\n",
       " 'put',\n",
       " 'finger\\nin',\n",
       " 'own',\n",
       " 'I',\n",
       " 'have',\n",
       " 'greater\\nknowledge',\n",
       " 'you.\\n\\n*****\\n\\nAnd',\n",
       " 'I',\n",
       " 'your',\n",
       " 'bodies,\\nnor',\n",
       " 'wind.\\n\\nIt',\n",
       " 'thing',\n",
       " 'crawls',\n",
       " 'into\\ndarkness',\n",
       " 'safety,\\n\\nBut',\n",
       " 'thing',\n",
       " 'spirit',\n",
       " 'earth',\n",
       " 'moves',\n",
       " 'seek',\n",
       " 'but',\n",
       " 'their',\n",
       " 'I',\n",
       " 'would',\n",
       " 'have',\n",
       " 'lives,',\n",
       " 'conceived\\nin',\n",
       " 'mist',\n",
       " 'who',\n",
       " 'knows',\n",
       " 'but',\n",
       " 'would',\n",
       " 'I',\n",
       " 'have',\n",
       " 'remember',\n",
       " 'feeble',\n",
       " 'your',\n",
       " 'that',\n",
       " 'that',\n",
       " 'city',\n",
       " 'there',\n",
       " 'but',\n",
       " 'would',\n",
       " 'cease',\n",
       " 'see',\n",
       " 'would',\n",
       " 'sound.\\n\\nBut',\n",
       " 'that',\n",
       " 'your',\n",
       " 'eyes',\n",
       " 'shall',\n",
       " 'that',\n",
       " 'it,\\n\\nAnd',\n",
       " 'clay',\n",
       " 'that',\n",
       " 'fills',\n",
       " 'your',\n",
       " 'ears',\n",
       " 'those',\n",
       " 'that',\n",
       " 'shall',\n",
       " 'shall',\n",
       " 'shall',\n",
       " 'nor',\n",
       " 'been',\n",
       " 'that',\n",
       " 'day',\n",
       " 'shall',\n",
       " 'know',\n",
       " 'things,\\n\\nAnd',\n",
       " 'shall',\n",
       " 'you\\nwould',\n",
       " 'things',\n",
       " 'he',\n",
       " 'him,',\n",
       " 'he',\n",
       " 'he',\n",
       " 'over',\n",
       " 'is',\n",
       " 'wind',\n",
       " 'are',\n",
       " 'direction;\\n\\nYet',\n",
       " 'my',\n",
       " 'captain',\n",
       " 'my',\n",
       " 'mariners,',\n",
       " 'who',\n",
       " 'have',\n",
       " 'heard',\n",
       " 'am',\n",
       " 'and\\nonce',\n",
       " 'mother',\n",
       " 'her',\n",
       " 'her',\n",
       " 'day',\n",
       " 'is',\n",
       " 'us',\n",
       " 'even',\n",
       " 'the\\nwater-lily',\n",
       " 'its',\n",
       " 'own',\n",
       " 'tomorrow.\\n\\nWhat',\n",
       " 'given',\n",
       " 'us',\n",
       " 'shall',\n",
       " 'it',\n",
       " 'not,',\n",
       " 'must\\nwe',\n",
       " 'come',\n",
       " 'together',\n",
       " 'together',\n",
       " 'unto',\n",
       " 'that',\n",
       " 'I',\n",
       " 'shall',\n",
       " 'come',\n",
       " 'my',\n",
       " 'longing',\n",
       " 'body.\\n\\nA',\n",
       " 'while,',\n",
       " 'shall',\n",
       " 'you',\n",
       " 'I',\n",
       " 'you.\\n\\nIt',\n",
       " 'but',\n",
       " 'have',\n",
       " 'I',\n",
       " 'your',\n",
       " 'have\\nbuilt',\n",
       " 'now',\n",
       " 'has',\n",
       " 'over,',\n",
       " 'it',\n",
       " 'is',\n",
       " 'is',\n",
       " 'us',\n",
       " 'has',\n",
       " 'more,',\n",
       " 'shall',\n",
       " 'speak',\n",
       " 'you',\n",
       " 'shall',\n",
       " 'sing',\n",
       " 'me',\n",
       " 'shall',\n",
       " 'tower',\n",
       " 'he',\n",
       " 'eastward.\\n\\nAnd',\n",
       " 'cry',\n",
       " 'came',\n",
       " 'it',\n",
       " 'into',\n",
       " 'dusk\\nand',\n",
       " 'carried',\n",
       " 'over',\n",
       " 'sea',\n",
       " 'like',\n",
       " 'ship',\n",
       " 'it',\n",
       " 'into\\nthe',\n",
       " 'when',\n",
       " 'were',\n",
       " 'alone',\n",
       " 'her',\n",
       " 'heart',\n",
       " 'his',\n",
       " 'while,',\n",
       " 'moment',\n",
       " 'rest',\n",
       " 'wind,',\n",
       " 'another',\n",
       " 'shall',\n",
       " 'PROPHET',\n",
       " 'should',\n",
       " '',\n",
       " 'old',\n",
       " 'will\\nbe',\n",
       " 'that',\n",
       " 'no',\n",
       " 'one',\n",
       " 'it',\n",
       " 'is',\n",
       " 'you',\n",
       " 'you',\n",
       " 'you',\n",
       " 'not',\n",
       " 'is',\n",
       " 'nearly',\n",
       " 'is',\n",
       " 'FULL',\n",
       " 'GUTENBERG',\n",
       " 'DISTRIBUTE',\n",
       " 'work\\n(or',\n",
       " 'way',\n",
       " 'you',\n",
       " 'file',\n",
       " 'By',\n",
       " 'you',\n",
       " 'that',\n",
       " 'you',\n",
       " 'have',\n",
       " 'license',\n",
       " 'and',\n",
       " 'intellectual',\n",
       " 'you',\n",
       " 'not',\n",
       " 'you',\n",
       " 'cease',\n",
       " 'and',\n",
       " 'you',\n",
       " 'and',\n",
       " 'you',\n",
       " 'not',\n",
       " 'bound\\nby',\n",
       " 'you',\n",
       " 'you',\n",
       " 'as',\n",
       " 'is',\n",
       " 'It',\n",
       " 'only',\n",
       " 'way',\n",
       " 'an',\n",
       " 'are',\n",
       " 'that',\n",
       " 'you',\n",
       " 'agreement.',\n",
       " 'are',\n",
       " 'things',\n",
       " 'you',\n",
       " 'if',\n",
       " 'you',\n",
       " 'and',\n",
       " '(\"the\\nFoundation\"',\n",
       " 'are',\n",
       " 'an',\n",
       " 'is',\n",
       " 'and',\n",
       " 'you',\n",
       " 'are',\n",
       " 'you',\n",
       " 'performing,\\ndisplaying',\n",
       " 'as',\n",
       " 'long',\n",
       " 'are',\n",
       " 'you',\n",
       " 'will',\n",
       " 'promoting\\nfree',\n",
       " 'sharing',\n",
       " 'its',\n",
       " 'when\\nyou',\n",
       " 'it',\n",
       " 'others.\\n\\n1.D.',\n",
       " 'you',\n",
       " 'are',\n",
       " 'govern\\nwhat',\n",
       " 'you',\n",
       " 'can',\n",
       " 'you',\n",
       " 'are',\n",
       " 'your',\n",
       " 'before',\n",
       " 'displaying,',\n",
       " 'based',\n",
       " 'work.',\n",
       " 'no\\nrepresentations',\n",
       " 'outside',\n",
       " 'you',\n",
       " 'have',\n",
       " 'all',\n",
       " 'appear\\nprominently',\n",
       " 'which',\n",
       " 'which',\n",
       " '\"Project',\n",
       " 'is',\n",
       " 'is',\n",
       " '',\n",
       " 'eBook',\n",
       " 'is',\n",
       " '',\n",
       " 'most',\n",
       " 'no',\n",
       " 'and',\n",
       " 'almost',\n",
       " '',\n",
       " 'give',\n",
       " 'it',\n",
       " '',\n",
       " 'the',\n",
       " '',\n",
       " 'eBook',\n",
       " 'you',\n",
       " 'are',\n",
       " 'not',\n",
       " '',\n",
       " \"you'll\",\n",
       " 'have',\n",
       " 'the',\n",
       " 'the',\n",
       " 'country',\n",
       " 'you\\n',\n",
       " '',\n",
       " 'are',\n",
       " 'before',\n",
       " 'an',\n",
       " 'not',\n",
       " 'that',\n",
       " 'it',\n",
       " 'is',\n",
       " 'the\\ncopyright',\n",
       " 'the',\n",
       " 'can',\n",
       " 'and',\n",
       " 'anyone',\n",
       " 'United',\n",
       " 'without',\n",
       " 'you',\n",
       " 'are\\nredistributing',\n",
       " 'a',\n",
       " 'the',\n",
       " 'the',\n",
       " 'you',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'and',\n",
       " 'the',\n",
       " 'as',\n",
       " '1.E.9.\\n\\n1.E.3.',\n",
       " 'an',\n",
       " 'is',\n",
       " 'the',\n",
       " 'the',\n",
       " ...]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # iterating on a copy since removing will mess things up\n",
    "# your code here\n",
    "prophet[0:567]\n",
    "\n",
    "\n",
    "def remove_words(x):\n",
    "    for i in x:\n",
    "        y = x.remove(i[0:567]) \n",
    "    return x\n",
    "\n",
    "remove_words(prophet)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8zBCI-MFrJt1"
   },
   "source": [
    "If you look through the words, you will find that many words have a reference attached to them. For example, let's look at words 1 through 10.\n",
    "\n",
    "Expected output:\n",
    "\n",
    "````python\n",
    "            ['PROPHET\\n\\n|Almustafa,',\n",
    "             'the{7}',\n",
    "             'chosen',\n",
    "             'and',\n",
    "             'the\\nbeloved,',\n",
    "             'who',\n",
    "             'was',\n",
    "             'a',\n",
    "             'dawn',\n",
    "             'unto']\n",
    "\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7_7iXvZYrJt2"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lr-MA87urJt6"
   },
   "source": [
    "#### The next step is to create a function that will remove references. \n",
    "\n",
    "We will do this by splitting the string on the `{` character and keeping only the part before this character. Write your function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X3oq4IbtrJt7"
   },
   "outputs": [],
   "source": [
    "def reference(x):\n",
    "    '''\n",
    "    Input: A string\n",
    "    Output: The string with references removed\n",
    "    \n",
    "    Example:\n",
    "    Input: 'the{7}'\n",
    "    Output: 'the'\n",
    "    '''\n",
    "    \n",
    "    # your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HelnQ7CdrJuJ"
   },
   "source": [
    "Now that we have our function, use the `map()` function to apply this function to our book, The Prophet. Return the resulting list to a new list called `prophet_reference`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aP1L2CQ8rJuK"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZeXcGmk3rJuN"
   },
   "source": [
    "Another thing you may have noticed is that some words contain a line break. Let's write a function to split those words. Our function will return the string split on the character `\\n`. Write your function in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kxkA6s1ZrJuO"
   },
   "outputs": [],
   "source": [
    "def line_break(x):\n",
    "    '''\n",
    "    Input: A string\n",
    "    Output: A list of strings split on the line break (\\n) character\n",
    "        \n",
    "    Example:\n",
    "    Input: 'the\\nbeloved'\n",
    "    Output: ['the', 'beloved']\n",
    "    '''\n",
    "    \n",
    "    # your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vnnCEF35rJuR"
   },
   "source": [
    "Apply the `line_break` function to the `prophet_reference` list. Name the new list `prophet_line`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ez96gtU9rJuS"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9dhbACu6rJuW"
   },
   "source": [
    "If you look at the elements of `prophet_line`, you will see that the function returned lists and not strings. Our list is now a list of lists. Flatten the list using list comprehension. Assign this new list to `prophet_flat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WY6lb6SjrJuX"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y7nZFMWUrJua"
   },
   "source": [
    "# Challenge 2 - Filtering\n",
    "\n",
    "When printing out a few words from the book, we see that there are words that we may not want to keep if we choose to analyze the corpus of text. Below is a list of words that we would like to get rid of. Create a function that will return false if it contains a word from the list of words specified and true otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W0sZtfMGrJua"
   },
   "outputs": [],
   "source": [
    "def word_filter(x):\n",
    "    '''\n",
    "    Input: A string\n",
    "    Output: True if the word is not in the specified list \n",
    "    and False if the word is in the list.\n",
    "        \n",
    "    Example:\n",
    "    word list = ['and', 'the']\n",
    "    Input: 'and'\n",
    "    Output: False\n",
    "    \n",
    "    Input: 'John'\n",
    "    Output: True\n",
    "    '''\n",
    "    \n",
    "    word_list = ['and', 'the', 'a', 'an']\n",
    "    \n",
    "    # your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mg1jXYJ2rJud"
   },
   "source": [
    "Use the `filter()` function to filter out the words speficied in the `word_filter()` function. Store the filtered list in the variable `prophet_filter`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xxlJQ0jurJue"
   },
   "source": [
    "# Bonus Challenge\n",
    "\n",
    "Rewrite the `word_filter` function above to not be case sensitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LHpgo8N3rJuf"
   },
   "outputs": [],
   "source": [
    "def word_filter_case(x):\n",
    "   \n",
    "    word_list = ['and', 'the', 'a', 'an']\n",
    "    \n",
    "    # your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fi_wuSQlrJuj"
   },
   "source": [
    "# Challenge 3 - Reducing\n",
    "\n",
    "#### Now that we have significantly cleaned up our text corpus, let's use the `reduce()` function to put the words back together into one long string separated by spaces. \n",
    "\n",
    "We will start by writing a function that takes two strings and concatenates them together with a space between the two strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wOmYQ9VorJuk"
   },
   "outputs": [],
   "source": [
    "def concat_space(a, b):\n",
    "    '''\n",
    "    Input:Two strings\n",
    "    Output: A single string separated by a space\n",
    "        \n",
    "    Example:\n",
    "    Input: 'John', 'Smith'\n",
    "    Output: 'John Smith'\n",
    "    '''\n",
    "    \n",
    "    # your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6-XVJqmRrJuo"
   },
   "source": [
    "Use the function above to reduce the text corpus in the list `prophet_filter` into a single string. Assign this new string to the variable `prophet_string`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0aPI0Wd_rJup"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vfU7l1AQrJus"
   },
   "source": [
    "# Challenge 4 - Applying Functions to DataFrames\n",
    "\n",
    "#### Our next step is to use the apply function to a dataframe and transform all cells.\n",
    "\n",
    "To do this, we will connect to Ironhack's database and retrieve the data from the *pollution* database. Select the *beijing_pollution* table and retrieve its data. The data is also available at https://archive.ics.uci.edu/ml/datasets/Beijing+PM2.5+Data#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b3GvzGWUrJut"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8297k0TYrJuv"
   },
   "source": [
    "Let's look at the data using the `head()` function.\n",
    "\n",
    "Expected output:\n",
    "\n",
    ">\n",
    ">|    |   No |   year |   month |   day |   hour |   pm2.5 |   DEWP |   TEMP |   PRES | cbwd   |   Iws |   Is |   Ir |\n",
    "|---:|-----:|-------:|--------:|------:|-------:|--------:|-------:|-------:|-------:|:-------|------:|-----:|-----:|\n",
    "|  0 |    1 |   2010 |       1 |     1 |      0 |     nan |    -21 |    -11 |   1021 | NW     |  1.79 |    0 |    0 |\n",
    "|  1 |    2 |   2010 |       1 |     1 |      1 |     nan |    -21 |    -12 |   1020 | NW     |  4.92 |    0 |    0 |\n",
    "|  2 |    3 |   2010 |       1 |     1 |      2 |     nan |    -21 |    -11 |   1019 | NW     |  6.71 |    0 |    0 |\n",
    "|  3 |    4 |   2010 |       1 |     1 |      3 |     nan |    -21 |    -14 |   1019 | NW     |  9.84 |    0 |    0 |\n",
    "|  4 |    5 |   2010 |       1 |     1 |      4 |     nan |    -20 |    -12 |   1018 | NW     | 12.97 |    0 |    0 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5qTif-IurJuw"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ByENRWf6rJu4"
   },
   "source": [
    "The next step is to create a function that divides a cell by 24 to produce an hourly figure. Write the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YOST-vh5rJu5"
   },
   "outputs": [],
   "source": [
    "def hourly(x):\n",
    "    '''\n",
    "    Input: A numerical value\n",
    "    Output: The value divided by 24\n",
    "        \n",
    "    Example:\n",
    "    Input: 48\n",
    "    Output: 2.0\n",
    "    '''\n",
    "    \n",
    "    # your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yvcnm30PrJu_"
   },
   "source": [
    "Apply this function to the columns `Iws`, `Is`, and `Ir`. Store this new dataframe in the variable `pm25_hourly`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NEjehpzGrJvA"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a_HbwX40rJvG"
   },
   "source": [
    "#### Our last challenge will be to create an aggregate function and apply it to a select group of columns in our dataframe.\n",
    "\n",
    "Write a function that returns the standard deviation of a column divided by the length of a column minus 1. Since we are using pandas, do not use the `len()` function. One alternative is to use `count()`. Also, use the numpy version of standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XA19K30SrJvI"
   },
   "outputs": [],
   "source": [
    "def sample_sd(x):\n",
    "    '''\n",
    "    Input: A Pandas series of values\n",
    "    Output: the standard deviation divided by the number of elements in the series\n",
    "        \n",
    "    Example:\n",
    "    Input: pd.Series([1,2,3,4])\n",
    "    Output: 0.3726779962\n",
    "    '''\n",
    "    \n",
    "    # your code here"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "main.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
